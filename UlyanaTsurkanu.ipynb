{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7fXHyTtPHBaFuHKqWyJmm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# ========================================\n","# Homework 1: Regex + NLP Preprocessing\n","# Text: Travel Blog Road Trip\n","# ========================================\n","\n","# 1. Data & Context\n","\n","text = \"\"\"\n","Last summer, on July 12, 2025, I embarked on a road trip across the Pacific Northwest. It was something I had been planning for months, and I shared my itinerary with fellow travelers at wanderlustclub@gmail.com.\n","\n","The journey started in Seattle, Washington. I stayed at a cozy Airbnb (contact: +1-206-555-3142) near Pike Place Market. The first morning, I explored the iconic market and tried some fresh seafood. My favorite stall, “Ocean Delights,” even gave me a card to contact them for future orders: ocean.delights@seafoodmail.com.\n","\n","From Seattle, I drove along the scenic Highway 101, stopping at several viewpoints. On July 15, 2025, I reached Olympic National Park. The hiking trails were breathtaking. I met other hikers and shared photos using hashtags like #PNWAdventures and #HikeLife. Some shared their own blogs, including https://explorenorthwest.com/trails-guide.\n","\n","During the trip, I made a few hotel reservations. One particularly memorable stay was at the Rainier Lodge, booked via https://rainierlodge.com/reservations. They confirmed my booking for July 17–19, 2025, and also gave a local contact number (+1-360-555-7281) in case of emergencies.\n","\n","Portland, Oregon, was my next stop. I joined a guided food tour and tried some amazing local dishes. The guide suggested reaching out to him at tastytrails@foodies.net for personalized recommendations. Over three days, I also visited Powell’s City of Books and caught a small live music event at https://portlandmusiclive.org/events.\n","\n","I logged daily expenses in a notebook. Some numbers to remember:\n","Gas for the trip: $342\n","Hotels booked: 4\n","Meals: $276\n","National park entrance fees: $58\n","\n","While driving through Oregon’s coastline, I met a family who was on vacation from New York. They shared their contact info for future travel plans: +1-917-555-6620. They also recommended using the hashtag #CoastalWonders to find the best photo spots.\n","\n","One challenge I faced was sudden rain near Cannon Beach. I tweeted for advice at @TravelTipsOfficial and got multiple responses, some including URLs like https://weatheralerts.com/pnw.\n","\n","The trip concluded in Portland on July 22, 2025, where I took a flight back home. I documented the entire journey on my blog, with photos, travel tips, and budget breakdowns: https://mytraveljournal.net/pnw-road-trip. Readers can also email me at myjournal.contact@travelsite.org for itinerary templates or advice.\n","\n","Some highlights worth mentioning:\n","Hiking miles covered: 42.3 miles\n","Total cities visited: 3 (Seattle, Olympic NP, Portland)\n","Social media posts shared: 57\n","\n","If anyone plans a similar trip, I highly recommend following these hashtags for inspiration: #WanderlustPNW, #NatureLovers, and #RoadTripGoals. For emergency contacts, always save local numbers, like the Seattle Airbnb (+1-206-555-3142) and Rainier Lodge (+1-360-555-7281).\n","\n","Finally, my favorite moment was watching the sunset over Cannon Beach on July 18, 2025. It’s a memory I’ll cherish forever and a reminder that the Pacific Northwest is a paradise for nature lovers.\n","\"\"\"\n","\n","# Data and Context comment\n","# Source: ChatGPT generated travel blog text by my request.\n","# Reason: I chose ChatGPT to create a suitable travel blog text with various linguistic patterns because it can generate really good text, perfect for coding practice.\n","\n","\n","# 2️ Regex Extraction\n","\n","import re\n","\n","patterns = {\n","    \"Emails\": r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\",\n","    \"PhoneNumbers\": r\"\\+?\\d{1,3}[-\\s]?\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4}\",\n","    \"Dates\": r\"\\b\\d{1,2}/?\\d{1,2}/?\\d{2,4}\\b|July\\s\\d{1,2},\\s\\d{4}\",\n","    \"Hashtags\": r\"#\\w+\",\n","    \"URLs\": r\"https?://[A-Za-z0-9./_-]+\",\n","    \"Numbers\": r\"\\b\\d+(?:\\.\\d+)?\\b\"\n","}\n","\n","for label, pat in patterns.items():\n","    matches = re.findall(pat, text)\n","    print(f\"--- {label} ---\")\n","    print(matches)\n","\n","\n","# 3️ NLP Preprocessing\n","\n","from collections import Counter\n","\n","def tokenize(text):\n","    return re.findall(r\"[A-Za-z]+\", text)\n","\n","def normalize(tokens):\n","    return [t.lower() for t in tokens]\n","\n","STOP_WORDS = {\n","    'a','an','the','and','or','of','on','in','to','is','are','as','from','this','it','i','you','at','for','with','while','if','my','they','their','also'\n","}\n","\n","def remove_stopwords(tokens):\n","    return [t for t in tokens if t not in STOP_WORDS]\n","\n","def toy_lemmatize(token):\n","    if token.endswith('ies') and len(token) > 4:\n","        return token[:-3]+'y'\n","    if token.endswith('s') and len(token) > 3:\n","        return token[:-1]\n","    if token.endswith('ing') and len(token) > 5:\n","        return token[:-3]\n","    return token\n","\n","def pipeline(text):\n","    tokens = tokenize(text)\n","    tokens = normalize(tokens)\n","    tokens = remove_stopwords(tokens)\n","    tokens = [toy_lemmatize(t) for t in tokens]\n","    return tokens\n","\n","processed_tokens = pipeline(text)\n","print(\"\\nProcessed tokens (first 40):\", processed_tokens[:40])\n","\n","top_tokens = Counter(processed_tokens).most_common(15)\n","print(\"\\nTop 15 tokens:\", top_tokens)\n","\n","\n","# 4️ Regex + NLP Combo\n","\n","clean_text = re.sub(r\"\\s+\", \" \", text)\n","number_noun_pairs = re.findall(r\"(\\d+(?:\\.\\d+)?)\\s+([A-Za-z]+)\", clean_text)\n","print(\"\\nNumber–Noun pairs:\", number_noun_pairs)\n","\n","\n","# 5️ Visualization\n","\n","import matplotlib.pyplot as plt\n","\n","words, freqs = zip(*top_tokens)\n","plt.bar(words, freqs)\n","plt.xticks(rotation=45)\n","plt.title(\"Top 15 Tokens After Preprocessing\")\n","plt.ylabel(\"Frequency\")\n","plt.show()\n","\n","comments = \"\"\"\n","6️ Comments explaining each step:\n","\n","Regex extraction. I used a set of patterns (emails, phone numbers, dates, hashtags, URLs, numbers) to automatically extract entities from the text.\n","The results are displayed as lists, which makes verification easy.\n","\n","NLP preprocessing. I chose simple rule-based lemmatization (the toy_lemmatize function) instead of aggressive stemming to keep the word bases more readable\n","(for example, \"hiking\" - \"hik\" would be less informative).\n","\n","Regex + NLP combo. For the combined extraction, I found (number, following word) pairs in the text this is useful for linking numbers with entities\n","(like costs, distances, or counts). This rule quickly produced useful pairs but may include false matches when punctuation or parentheses appear near numbers.\n","\n","Visualization. I created a bar chart of the top 15 token frequencies after preprocessing to visually show the dominant words.\n","The chart helps quickly identify which words occur most often.\n","\n","Reproducibility. The notebook runs from top to bottom and includes the text itself as a variable (text),\n","so anyone can reproduce the experiment without external files.\n","All key results (lists of matches, top tokens, number–noun pairs, and the chart) are displayed in cells and\n","it’s enough to run the notebook sequentially.\n","\"\"\"\n","\n","print(comments)\n","\n","\n","\n","\n","# 7 Report\n","\n","report = \"\"\"\n","Report Summary:\n","For this assignment, I followed the instructions provided by my teacher to extract and preprocess text using regex and basic NLP techniques. The process started with finding a suitable text containing many patterns like emails, URLs, hashtags, dates, and numbers.\n","I searched news articles and Twitter posts but couldn’t find anything suitable, so I used ChatGPT to generate a travel blog, which worked perfectly for practicing the code.\n","The challenging part for me was lemmatization. I tried to convert words to their base forms, which is more complicated than simple stemming since it requires understanding grammar and word meaning. My implementation was a simplified version using rules, but I think it was worth it because it made the text look cleaner.\n","Overall, I enjoyed working on this task. It was the first time I did something like this, so especially with lemmatization, I asked AI to explain it to me. This task helped me understand how regex and lightweight NLP can structure real-world text. For example, regex successfully extracted emails, phone numbers, dates, URLs, hashtags, and numbers, while NLP preprocessing produced meaningful tokens like seattle, portland, hiking, and trip.\n","\"\"\"\n","print(report)\n"],"metadata":{"id":"-Ed8I0qom2xt"},"execution_count":null,"outputs":[]}]}